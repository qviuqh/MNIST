{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d66dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Tải dữ liệu\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Tiền xử lý\n",
    "x_train = x_train.reshape(-1, 784).astype('float32') / 255.0\n",
    "x_test  = x_test.reshape(-1, 784).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c8d460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap='gray')\n",
    "plt.title('First image in training set')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "766fc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # chống overflow\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-8)) / m\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eea077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):\n",
    "        # Khởi tạo trọng số và bias\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.z1 = np.dot(x, self.W1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        m = y_true.shape[0]\n",
    "        dz2 = self.a2 - y_true\n",
    "        dW2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "\n",
    "        da1 = np.dot(dz2, self.W2.T)\n",
    "        dz1 = da1 * relu_derivative(self.z1)\n",
    "        dW1 = np.dot(self.x.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Cập nhật\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "\n",
    "    def train(self, x_train, y_train, x_test, y_test, epochs=20):\n",
    "        for epoch in range(epochs):\n",
    "            y_pred = self.forward(x_train)\n",
    "            loss = cross_entropy_loss(y_train, y_pred)\n",
    "            self.backward(y_train)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                test_pred = self.forward(x_test)\n",
    "                acc = accuracy(y_test, test_pred)\n",
    "                print(f\"Epoch {epoch+1:02d}: Loss = {loss:.4f}, Test Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c9ee16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: Loss = 2.3037, Test Accuracy = 0.2115\n",
      "Epoch 02: Loss = 2.3001, Test Accuracy = 0.3165\n",
      "Epoch 03: Loss = 2.2966, Test Accuracy = 0.4191\n",
      "Epoch 04: Loss = 2.2927, Test Accuracy = 0.4952\n",
      "Epoch 05: Loss = 2.2882, Test Accuracy = 0.5400\n",
      "Epoch 06: Loss = 2.2828, Test Accuracy = 0.5657\n",
      "Epoch 07: Loss = 2.2762, Test Accuracy = 0.5835\n",
      "Epoch 08: Loss = 2.2681, Test Accuracy = 0.5925\n",
      "Epoch 09: Loss = 2.2581, Test Accuracy = 0.5979\n",
      "Epoch 10: Loss = 2.2457, Test Accuracy = 0.6018\n",
      "Epoch 11: Loss = 2.2304, Test Accuracy = 0.6025\n",
      "Epoch 12: Loss = 2.2113, Test Accuracy = 0.6019\n",
      "Epoch 13: Loss = 2.1879, Test Accuracy = 0.6041\n",
      "Epoch 14: Loss = 2.1594, Test Accuracy = 0.6054\n",
      "Epoch 15: Loss = 2.1248, Test Accuracy = 0.6111\n",
      "Epoch 16: Loss = 2.0836, Test Accuracy = 0.6192\n",
      "Epoch 17: Loss = 2.0351, Test Accuracy = 0.6310\n",
      "Epoch 18: Loss = 1.9792, Test Accuracy = 0.6416\n",
      "Epoch 19: Loss = 1.9160, Test Accuracy = 0.6561\n",
      "Epoch 20: Loss = 1.8462, Test Accuracy = 0.6702\n",
      "Epoch 21: Loss = 1.7711, Test Accuracy = 0.6814\n",
      "Epoch 22: Loss = 1.6924, Test Accuracy = 0.6923\n",
      "Epoch 23: Loss = 1.6120, Test Accuracy = 0.7015\n",
      "Epoch 24: Loss = 1.5320, Test Accuracy = 0.7095\n",
      "Epoch 25: Loss = 1.4543, Test Accuracy = 0.7185\n",
      "Epoch 26: Loss = 1.3802, Test Accuracy = 0.7299\n",
      "Epoch 27: Loss = 1.3107, Test Accuracy = 0.7430\n",
      "Epoch 28: Loss = 1.2463, Test Accuracy = 0.7516\n",
      "Epoch 29: Loss = 1.1869, Test Accuracy = 0.7620\n",
      "Epoch 30: Loss = 1.1326, Test Accuracy = 0.7690\n",
      "Epoch 31: Loss = 1.0830, Test Accuracy = 0.7761\n",
      "Epoch 32: Loss = 1.0377, Test Accuracy = 0.7826\n",
      "Epoch 33: Loss = 0.9963, Test Accuracy = 0.7896\n",
      "Epoch 34: Loss = 0.9585, Test Accuracy = 0.7953\n",
      "Epoch 35: Loss = 0.9239, Test Accuracy = 0.7987\n",
      "Epoch 36: Loss = 0.8922, Test Accuracy = 0.8030\n",
      "Epoch 37: Loss = 0.8632, Test Accuracy = 0.8066\n",
      "Epoch 38: Loss = 0.8364, Test Accuracy = 0.8108\n",
      "Epoch 39: Loss = 0.8117, Test Accuracy = 0.8152\n",
      "Epoch 40: Loss = 0.7890, Test Accuracy = 0.8191\n",
      "Epoch 41: Loss = 0.7679, Test Accuracy = 0.8220\n",
      "Epoch 42: Loss = 0.7484, Test Accuracy = 0.8250\n",
      "Epoch 43: Loss = 0.7303, Test Accuracy = 0.8281\n",
      "Epoch 44: Loss = 0.7134, Test Accuracy = 0.8308\n",
      "Epoch 45: Loss = 0.6977, Test Accuracy = 0.8334\n",
      "Epoch 46: Loss = 0.6831, Test Accuracy = 0.8358\n",
      "Epoch 47: Loss = 0.6693, Test Accuracy = 0.8388\n",
      "Epoch 48: Loss = 0.6565, Test Accuracy = 0.8425\n",
      "Epoch 49: Loss = 0.6444, Test Accuracy = 0.8443\n",
      "Epoch 50: Loss = 0.6330, Test Accuracy = 0.8464\n",
      "Epoch 51: Loss = 0.6222, Test Accuracy = 0.8487\n",
      "Epoch 52: Loss = 0.6121, Test Accuracy = 0.8508\n",
      "Epoch 53: Loss = 0.6025, Test Accuracy = 0.8523\n",
      "Epoch 54: Loss = 0.5934, Test Accuracy = 0.8538\n",
      "Epoch 55: Loss = 0.5848, Test Accuracy = 0.8555\n",
      "Epoch 56: Loss = 0.5766, Test Accuracy = 0.8583\n",
      "Epoch 57: Loss = 0.5688, Test Accuracy = 0.8595\n",
      "Epoch 58: Loss = 0.5614, Test Accuracy = 0.8606\n",
      "Epoch 59: Loss = 0.5543, Test Accuracy = 0.8613\n",
      "Epoch 60: Loss = 0.5475, Test Accuracy = 0.8624\n",
      "Epoch 61: Loss = 0.5411, Test Accuracy = 0.8648\n",
      "Epoch 62: Loss = 0.5349, Test Accuracy = 0.8665\n",
      "Epoch 63: Loss = 0.5289, Test Accuracy = 0.8677\n",
      "Epoch 64: Loss = 0.5232, Test Accuracy = 0.8689\n",
      "Epoch 65: Loss = 0.5177, Test Accuracy = 0.8705\n",
      "Epoch 66: Loss = 0.5125, Test Accuracy = 0.8717\n",
      "Epoch 67: Loss = 0.5074, Test Accuracy = 0.8721\n",
      "Epoch 68: Loss = 0.5025, Test Accuracy = 0.8727\n",
      "Epoch 69: Loss = 0.4978, Test Accuracy = 0.8740\n",
      "Epoch 70: Loss = 0.4933, Test Accuracy = 0.8751\n",
      "Epoch 71: Loss = 0.4889, Test Accuracy = 0.8759\n",
      "Epoch 72: Loss = 0.4847, Test Accuracy = 0.8766\n",
      "Epoch 73: Loss = 0.4807, Test Accuracy = 0.8778\n",
      "Epoch 74: Loss = 0.4767, Test Accuracy = 0.8782\n",
      "Epoch 75: Loss = 0.4729, Test Accuracy = 0.8794\n",
      "Epoch 76: Loss = 0.4692, Test Accuracy = 0.8806\n",
      "Epoch 77: Loss = 0.4657, Test Accuracy = 0.8814\n",
      "Epoch 78: Loss = 0.4622, Test Accuracy = 0.8818\n",
      "Epoch 79: Loss = 0.4589, Test Accuracy = 0.8827\n",
      "Epoch 80: Loss = 0.4557, Test Accuracy = 0.8836\n",
      "Epoch 81: Loss = 0.4525, Test Accuracy = 0.8844\n",
      "Epoch 82: Loss = 0.4495, Test Accuracy = 0.8853\n",
      "Epoch 83: Loss = 0.4465, Test Accuracy = 0.8860\n",
      "Epoch 84: Loss = 0.4437, Test Accuracy = 0.8860\n",
      "Epoch 85: Loss = 0.4409, Test Accuracy = 0.8868\n",
      "Epoch 86: Loss = 0.4382, Test Accuracy = 0.8872\n",
      "Epoch 87: Loss = 0.4355, Test Accuracy = 0.8880\n",
      "Epoch 88: Loss = 0.4330, Test Accuracy = 0.8882\n",
      "Epoch 89: Loss = 0.4305, Test Accuracy = 0.8885\n",
      "Epoch 90: Loss = 0.4281, Test Accuracy = 0.8891\n",
      "Epoch 91: Loss = 0.4257, Test Accuracy = 0.8896\n",
      "Epoch 92: Loss = 0.4234, Test Accuracy = 0.8900\n",
      "Epoch 93: Loss = 0.4212, Test Accuracy = 0.8906\n",
      "Epoch 94: Loss = 0.4190, Test Accuracy = 0.8913\n",
      "Epoch 95: Loss = 0.4169, Test Accuracy = 0.8914\n",
      "Epoch 96: Loss = 0.4149, Test Accuracy = 0.8917\n",
      "Epoch 97: Loss = 0.4129, Test Accuracy = 0.8921\n",
      "Epoch 98: Loss = 0.4109, Test Accuracy = 0.8927\n",
      "Epoch 99: Loss = 0.4090, Test Accuracy = 0.8929\n",
      "Epoch 100: Loss = 0.4071, Test Accuracy = 0.8934\n",
      "Epoch 101: Loss = 0.4053, Test Accuracy = 0.8941\n",
      "Epoch 102: Loss = 0.4035, Test Accuracy = 0.8945\n",
      "Epoch 103: Loss = 0.4018, Test Accuracy = 0.8952\n",
      "Epoch 104: Loss = 0.4001, Test Accuracy = 0.8955\n",
      "Epoch 105: Loss = 0.3984, Test Accuracy = 0.8959\n",
      "Epoch 106: Loss = 0.3968, Test Accuracy = 0.8962\n",
      "Epoch 107: Loss = 0.3952, Test Accuracy = 0.8963\n",
      "Epoch 108: Loss = 0.3936, Test Accuracy = 0.8965\n",
      "Epoch 109: Loss = 0.3921, Test Accuracy = 0.8972\n",
      "Epoch 110: Loss = 0.3906, Test Accuracy = 0.8974\n",
      "Epoch 111: Loss = 0.3892, Test Accuracy = 0.8976\n",
      "Epoch 112: Loss = 0.3878, Test Accuracy = 0.8979\n",
      "Epoch 113: Loss = 0.3864, Test Accuracy = 0.8984\n",
      "Epoch 114: Loss = 0.3850, Test Accuracy = 0.8989\n",
      "Epoch 115: Loss = 0.3836, Test Accuracy = 0.8994\n",
      "Epoch 116: Loss = 0.3823, Test Accuracy = 0.8996\n",
      "Epoch 117: Loss = 0.3810, Test Accuracy = 0.8999\n",
      "Epoch 118: Loss = 0.3798, Test Accuracy = 0.9001\n",
      "Epoch 119: Loss = 0.3785, Test Accuracy = 0.9006\n",
      "Epoch 120: Loss = 0.3773, Test Accuracy = 0.9006\n",
      "Epoch 121: Loss = 0.3761, Test Accuracy = 0.9005\n",
      "Epoch 122: Loss = 0.3749, Test Accuracy = 0.9007\n",
      "Epoch 123: Loss = 0.3738, Test Accuracy = 0.9010\n",
      "Epoch 124: Loss = 0.3726, Test Accuracy = 0.9009\n",
      "Epoch 125: Loss = 0.3715, Test Accuracy = 0.9009\n",
      "Epoch 126: Loss = 0.3704, Test Accuracy = 0.9014\n",
      "Epoch 127: Loss = 0.3693, Test Accuracy = 0.9016\n",
      "Epoch 128: Loss = 0.3683, Test Accuracy = 0.9014\n",
      "Epoch 129: Loss = 0.3672, Test Accuracy = 0.9017\n",
      "Epoch 130: Loss = 0.3662, Test Accuracy = 0.9019\n",
      "Epoch 131: Loss = 0.3652, Test Accuracy = 0.9019\n",
      "Epoch 132: Loss = 0.3642, Test Accuracy = 0.9021\n",
      "Epoch 133: Loss = 0.3632, Test Accuracy = 0.9022\n",
      "Epoch 134: Loss = 0.3622, Test Accuracy = 0.9027\n",
      "Epoch 135: Loss = 0.3613, Test Accuracy = 0.9027\n",
      "Epoch 136: Loss = 0.3604, Test Accuracy = 0.9031\n",
      "Epoch 137: Loss = 0.3594, Test Accuracy = 0.9031\n",
      "Epoch 138: Loss = 0.3585, Test Accuracy = 0.9032\n",
      "Epoch 139: Loss = 0.3576, Test Accuracy = 0.9036\n",
      "Epoch 140: Loss = 0.3567, Test Accuracy = 0.9036\n",
      "Epoch 141: Loss = 0.3559, Test Accuracy = 0.9037\n",
      "Epoch 142: Loss = 0.3550, Test Accuracy = 0.9039\n",
      "Epoch 143: Loss = 0.3542, Test Accuracy = 0.9040\n",
      "Epoch 144: Loss = 0.3533, Test Accuracy = 0.9041\n",
      "Epoch 145: Loss = 0.3525, Test Accuracy = 0.9042\n",
      "Epoch 146: Loss = 0.3517, Test Accuracy = 0.9044\n",
      "Epoch 147: Loss = 0.3509, Test Accuracy = 0.9045\n",
      "Epoch 148: Loss = 0.3501, Test Accuracy = 0.9047\n",
      "Epoch 149: Loss = 0.3493, Test Accuracy = 0.9051\n",
      "Epoch 150: Loss = 0.3486, Test Accuracy = 0.9055\n",
      "Epoch 151: Loss = 0.3478, Test Accuracy = 0.9055\n",
      "Epoch 152: Loss = 0.3470, Test Accuracy = 0.9056\n",
      "Epoch 153: Loss = 0.3463, Test Accuracy = 0.9059\n",
      "Epoch 154: Loss = 0.3456, Test Accuracy = 0.9060\n",
      "Epoch 155: Loss = 0.3448, Test Accuracy = 0.9062\n",
      "Epoch 156: Loss = 0.3441, Test Accuracy = 0.9064\n",
      "Epoch 157: Loss = 0.3434, Test Accuracy = 0.9067\n",
      "Epoch 158: Loss = 0.3427, Test Accuracy = 0.9068\n",
      "Epoch 159: Loss = 0.3420, Test Accuracy = 0.9069\n",
      "Epoch 160: Loss = 0.3413, Test Accuracy = 0.9072\n",
      "Epoch 161: Loss = 0.3406, Test Accuracy = 0.9072\n",
      "Epoch 162: Loss = 0.3400, Test Accuracy = 0.9077\n",
      "Epoch 163: Loss = 0.3393, Test Accuracy = 0.9078\n",
      "Epoch 164: Loss = 0.3386, Test Accuracy = 0.9079\n",
      "Epoch 165: Loss = 0.3380, Test Accuracy = 0.9085\n",
      "Epoch 166: Loss = 0.3373, Test Accuracy = 0.9086\n",
      "Epoch 167: Loss = 0.3367, Test Accuracy = 0.9090\n",
      "Epoch 168: Loss = 0.3361, Test Accuracy = 0.9091\n",
      "Epoch 169: Loss = 0.3354, Test Accuracy = 0.9091\n",
      "Epoch 170: Loss = 0.3348, Test Accuracy = 0.9092\n",
      "Epoch 171: Loss = 0.3342, Test Accuracy = 0.9092\n",
      "Epoch 172: Loss = 0.3336, Test Accuracy = 0.9095\n",
      "Epoch 173: Loss = 0.3330, Test Accuracy = 0.9097\n",
      "Epoch 174: Loss = 0.3324, Test Accuracy = 0.9103\n",
      "Epoch 175: Loss = 0.3318, Test Accuracy = 0.9105\n",
      "Epoch 176: Loss = 0.3312, Test Accuracy = 0.9105\n",
      "Epoch 177: Loss = 0.3306, Test Accuracy = 0.9106\n",
      "Epoch 178: Loss = 0.3301, Test Accuracy = 0.9107\n",
      "Epoch 179: Loss = 0.3295, Test Accuracy = 0.9109\n",
      "Epoch 180: Loss = 0.3289, Test Accuracy = 0.9111\n",
      "Epoch 181: Loss = 0.3283, Test Accuracy = 0.9115\n",
      "Epoch 182: Loss = 0.3278, Test Accuracy = 0.9115\n",
      "Epoch 183: Loss = 0.3272, Test Accuracy = 0.9118\n",
      "Epoch 184: Loss = 0.3267, Test Accuracy = 0.9118\n",
      "Epoch 185: Loss = 0.3261, Test Accuracy = 0.9119\n",
      "Epoch 186: Loss = 0.3256, Test Accuracy = 0.9121\n",
      "Epoch 187: Loss = 0.3251, Test Accuracy = 0.9122\n",
      "Epoch 188: Loss = 0.3245, Test Accuracy = 0.9123\n",
      "Epoch 189: Loss = 0.3240, Test Accuracy = 0.9123\n",
      "Epoch 190: Loss = 0.3235, Test Accuracy = 0.9123\n",
      "Epoch 191: Loss = 0.3230, Test Accuracy = 0.9125\n",
      "Epoch 192: Loss = 0.3224, Test Accuracy = 0.9126\n",
      "Epoch 193: Loss = 0.3219, Test Accuracy = 0.9127\n",
      "Epoch 194: Loss = 0.3214, Test Accuracy = 0.9128\n",
      "Epoch 195: Loss = 0.3209, Test Accuracy = 0.9131\n",
      "Epoch 196: Loss = 0.3204, Test Accuracy = 0.9132\n",
      "Epoch 197: Loss = 0.3199, Test Accuracy = 0.9133\n",
      "Epoch 198: Loss = 0.3194, Test Accuracy = 0.9136\n",
      "Epoch 199: Loss = 0.3189, Test Accuracy = 0.9137\n",
      "Epoch 200: Loss = 0.3185, Test Accuracy = 0.9140\n",
      "Epoch 201: Loss = 0.3180, Test Accuracy = 0.9142\n",
      "Epoch 202: Loss = 0.3175, Test Accuracy = 0.9142\n",
      "Epoch 203: Loss = 0.3170, Test Accuracy = 0.9142\n",
      "Epoch 204: Loss = 0.3166, Test Accuracy = 0.9144\n",
      "Epoch 205: Loss = 0.3161, Test Accuracy = 0.9147\n",
      "Epoch 206: Loss = 0.3156, Test Accuracy = 0.9148\n",
      "Epoch 207: Loss = 0.3152, Test Accuracy = 0.9148\n",
      "Epoch 208: Loss = 0.3147, Test Accuracy = 0.9148\n",
      "Epoch 209: Loss = 0.3142, Test Accuracy = 0.9147\n",
      "Epoch 210: Loss = 0.3138, Test Accuracy = 0.9147\n",
      "Epoch 211: Loss = 0.3133, Test Accuracy = 0.9147\n",
      "Epoch 212: Loss = 0.3129, Test Accuracy = 0.9147\n",
      "Epoch 213: Loss = 0.3124, Test Accuracy = 0.9146\n",
      "Epoch 214: Loss = 0.3120, Test Accuracy = 0.9148\n",
      "Epoch 215: Loss = 0.3116, Test Accuracy = 0.9149\n",
      "Epoch 216: Loss = 0.3111, Test Accuracy = 0.9149\n",
      "Epoch 217: Loss = 0.3107, Test Accuracy = 0.9151\n",
      "Epoch 218: Loss = 0.3103, Test Accuracy = 0.9152\n",
      "Epoch 219: Loss = 0.3098, Test Accuracy = 0.9151\n",
      "Epoch 220: Loss = 0.3094, Test Accuracy = 0.9152\n",
      "Epoch 221: Loss = 0.3090, Test Accuracy = 0.9154\n",
      "Epoch 222: Loss = 0.3085, Test Accuracy = 0.9154\n",
      "Epoch 223: Loss = 0.3081, Test Accuracy = 0.9158\n",
      "Epoch 224: Loss = 0.3077, Test Accuracy = 0.9161\n",
      "Epoch 225: Loss = 0.3073, Test Accuracy = 0.9161\n",
      "Epoch 226: Loss = 0.3069, Test Accuracy = 0.9164\n",
      "Epoch 227: Loss = 0.3065, Test Accuracy = 0.9165\n",
      "Epoch 228: Loss = 0.3061, Test Accuracy = 0.9164\n",
      "Epoch 229: Loss = 0.3057, Test Accuracy = 0.9165\n",
      "Epoch 230: Loss = 0.3052, Test Accuracy = 0.9165\n",
      "Epoch 231: Loss = 0.3048, Test Accuracy = 0.9165\n",
      "Epoch 232: Loss = 0.3044, Test Accuracy = 0.9166\n",
      "Epoch 233: Loss = 0.3040, Test Accuracy = 0.9166\n",
      "Epoch 234: Loss = 0.3036, Test Accuracy = 0.9166\n",
      "Epoch 235: Loss = 0.3033, Test Accuracy = 0.9170\n",
      "Epoch 236: Loss = 0.3029, Test Accuracy = 0.9170\n",
      "Epoch 237: Loss = 0.3025, Test Accuracy = 0.9172\n",
      "Epoch 238: Loss = 0.3021, Test Accuracy = 0.9174\n",
      "Epoch 239: Loss = 0.3017, Test Accuracy = 0.9173\n",
      "Epoch 240: Loss = 0.3013, Test Accuracy = 0.9174\n",
      "Epoch 241: Loss = 0.3009, Test Accuracy = 0.9176\n",
      "Epoch 242: Loss = 0.3005, Test Accuracy = 0.9176\n",
      "Epoch 243: Loss = 0.3002, Test Accuracy = 0.9177\n",
      "Epoch 244: Loss = 0.2998, Test Accuracy = 0.9179\n",
      "Epoch 245: Loss = 0.2994, Test Accuracy = 0.9181\n",
      "Epoch 246: Loss = 0.2990, Test Accuracy = 0.9181\n",
      "Epoch 247: Loss = 0.2987, Test Accuracy = 0.9181\n",
      "Epoch 248: Loss = 0.2983, Test Accuracy = 0.9181\n",
      "Epoch 249: Loss = 0.2979, Test Accuracy = 0.9183\n",
      "Epoch 250: Loss = 0.2975, Test Accuracy = 0.9184\n",
      "Epoch 251: Loss = 0.2972, Test Accuracy = 0.9183\n",
      "Epoch 252: Loss = 0.2968, Test Accuracy = 0.9186\n",
      "Epoch 253: Loss = 0.2964, Test Accuracy = 0.9186\n",
      "Epoch 254: Loss = 0.2961, Test Accuracy = 0.9187\n",
      "Epoch 255: Loss = 0.2957, Test Accuracy = 0.9187\n",
      "Epoch 256: Loss = 0.2954, Test Accuracy = 0.9186\n",
      "Epoch 257: Loss = 0.2950, Test Accuracy = 0.9187\n",
      "Epoch 258: Loss = 0.2946, Test Accuracy = 0.9187\n",
      "Epoch 259: Loss = 0.2943, Test Accuracy = 0.9189\n",
      "Epoch 260: Loss = 0.2939, Test Accuracy = 0.9190\n",
      "Epoch 261: Loss = 0.2936, Test Accuracy = 0.9193\n",
      "Epoch 262: Loss = 0.2932, Test Accuracy = 0.9193\n",
      "Epoch 263: Loss = 0.2929, Test Accuracy = 0.9193\n",
      "Epoch 264: Loss = 0.2925, Test Accuracy = 0.9193\n",
      "Epoch 265: Loss = 0.2922, Test Accuracy = 0.9194\n",
      "Epoch 266: Loss = 0.2918, Test Accuracy = 0.9194\n",
      "Epoch 267: Loss = 0.2915, Test Accuracy = 0.9195\n",
      "Epoch 268: Loss = 0.2911, Test Accuracy = 0.9198\n",
      "Epoch 269: Loss = 0.2908, Test Accuracy = 0.9199\n",
      "Epoch 270: Loss = 0.2904, Test Accuracy = 0.9199\n",
      "Epoch 271: Loss = 0.2901, Test Accuracy = 0.9199\n",
      "Epoch 272: Loss = 0.2898, Test Accuracy = 0.9203\n",
      "Epoch 273: Loss = 0.2894, Test Accuracy = 0.9205\n",
      "Epoch 274: Loss = 0.2891, Test Accuracy = 0.9204\n",
      "Epoch 275: Loss = 0.2887, Test Accuracy = 0.9207\n",
      "Epoch 276: Loss = 0.2884, Test Accuracy = 0.9207\n",
      "Epoch 277: Loss = 0.2881, Test Accuracy = 0.9207\n",
      "Epoch 278: Loss = 0.2877, Test Accuracy = 0.9208\n",
      "Epoch 279: Loss = 0.2874, Test Accuracy = 0.9209\n",
      "Epoch 280: Loss = 0.2871, Test Accuracy = 0.9210\n",
      "Epoch 281: Loss = 0.2867, Test Accuracy = 0.9211\n",
      "Epoch 282: Loss = 0.2864, Test Accuracy = 0.9213\n",
      "Epoch 283: Loss = 0.2861, Test Accuracy = 0.9213\n",
      "Epoch 284: Loss = 0.2858, Test Accuracy = 0.9214\n",
      "Epoch 285: Loss = 0.2854, Test Accuracy = 0.9214\n",
      "Epoch 286: Loss = 0.2851, Test Accuracy = 0.9213\n",
      "Epoch 287: Loss = 0.2848, Test Accuracy = 0.9213\n",
      "Epoch 288: Loss = 0.2845, Test Accuracy = 0.9213\n",
      "Epoch 289: Loss = 0.2841, Test Accuracy = 0.9215\n",
      "Epoch 290: Loss = 0.2838, Test Accuracy = 0.9215\n",
      "Epoch 291: Loss = 0.2835, Test Accuracy = 0.9216\n",
      "Epoch 292: Loss = 0.2832, Test Accuracy = 0.9217\n",
      "Epoch 293: Loss = 0.2829, Test Accuracy = 0.9218\n",
      "Epoch 294: Loss = 0.2826, Test Accuracy = 0.9219\n",
      "Epoch 295: Loss = 0.2822, Test Accuracy = 0.9221\n",
      "Epoch 296: Loss = 0.2819, Test Accuracy = 0.9224\n",
      "Epoch 297: Loss = 0.2816, Test Accuracy = 0.9226\n",
      "Epoch 298: Loss = 0.2813, Test Accuracy = 0.9227\n",
      "Epoch 299: Loss = 0.2810, Test Accuracy = 0.9232\n",
      "Epoch 300: Loss = 0.2807, Test Accuracy = 0.9235\n",
      "Epoch 301: Loss = 0.2804, Test Accuracy = 0.9237\n",
      "Epoch 302: Loss = 0.2800, Test Accuracy = 0.9239\n",
      "Epoch 303: Loss = 0.2797, Test Accuracy = 0.9240\n",
      "Epoch 304: Loss = 0.2794, Test Accuracy = 0.9243\n",
      "Epoch 305: Loss = 0.2791, Test Accuracy = 0.9244\n",
      "Epoch 306: Loss = 0.2788, Test Accuracy = 0.9245\n",
      "Epoch 307: Loss = 0.2785, Test Accuracy = 0.9244\n",
      "Epoch 308: Loss = 0.2782, Test Accuracy = 0.9247\n",
      "Epoch 309: Loss = 0.2779, Test Accuracy = 0.9248\n",
      "Epoch 310: Loss = 0.2776, Test Accuracy = 0.9250\n",
      "Epoch 311: Loss = 0.2773, Test Accuracy = 0.9250\n",
      "Epoch 312: Loss = 0.2770, Test Accuracy = 0.9251\n",
      "Epoch 313: Loss = 0.2767, Test Accuracy = 0.9249\n",
      "Epoch 314: Loss = 0.2764, Test Accuracy = 0.9249\n",
      "Epoch 315: Loss = 0.2761, Test Accuracy = 0.9252\n",
      "Epoch 316: Loss = 0.2758, Test Accuracy = 0.9252\n",
      "Epoch 317: Loss = 0.2755, Test Accuracy = 0.9252\n",
      "Epoch 318: Loss = 0.2752, Test Accuracy = 0.9253\n",
      "Epoch 319: Loss = 0.2749, Test Accuracy = 0.9254\n",
      "Epoch 320: Loss = 0.2746, Test Accuracy = 0.9255\n",
      "Epoch 321: Loss = 0.2743, Test Accuracy = 0.9255\n",
      "Epoch 322: Loss = 0.2740, Test Accuracy = 0.9255\n",
      "Epoch 323: Loss = 0.2737, Test Accuracy = 0.9258\n",
      "Epoch 324: Loss = 0.2734, Test Accuracy = 0.9259\n",
      "Epoch 325: Loss = 0.2731, Test Accuracy = 0.9261\n",
      "Epoch 326: Loss = 0.2729, Test Accuracy = 0.9261\n",
      "Epoch 327: Loss = 0.2726, Test Accuracy = 0.9262\n",
      "Epoch 328: Loss = 0.2723, Test Accuracy = 0.9262\n",
      "Epoch 329: Loss = 0.2720, Test Accuracy = 0.9262\n",
      "Epoch 330: Loss = 0.2717, Test Accuracy = 0.9262\n",
      "Epoch 331: Loss = 0.2714, Test Accuracy = 0.9262\n",
      "Epoch 332: Loss = 0.2711, Test Accuracy = 0.9262\n",
      "Epoch 333: Loss = 0.2708, Test Accuracy = 0.9262\n",
      "Epoch 334: Loss = 0.2705, Test Accuracy = 0.9264\n",
      "Epoch 335: Loss = 0.2703, Test Accuracy = 0.9264\n",
      "Epoch 336: Loss = 0.2700, Test Accuracy = 0.9264\n",
      "Epoch 337: Loss = 0.2697, Test Accuracy = 0.9265\n",
      "Epoch 338: Loss = 0.2694, Test Accuracy = 0.9265\n",
      "Epoch 339: Loss = 0.2691, Test Accuracy = 0.9266\n",
      "Epoch 340: Loss = 0.2688, Test Accuracy = 0.9267\n",
      "Epoch 341: Loss = 0.2685, Test Accuracy = 0.9267\n",
      "Epoch 342: Loss = 0.2683, Test Accuracy = 0.9269\n",
      "Epoch 343: Loss = 0.2680, Test Accuracy = 0.9271\n",
      "Epoch 344: Loss = 0.2677, Test Accuracy = 0.9273\n",
      "Epoch 345: Loss = 0.2674, Test Accuracy = 0.9273\n",
      "Epoch 346: Loss = 0.2671, Test Accuracy = 0.9274\n",
      "Epoch 347: Loss = 0.2669, Test Accuracy = 0.9275\n",
      "Epoch 348: Loss = 0.2666, Test Accuracy = 0.9277\n",
      "Epoch 349: Loss = 0.2663, Test Accuracy = 0.9277\n",
      "Epoch 350: Loss = 0.2660, Test Accuracy = 0.9277\n",
      "Epoch 351: Loss = 0.2657, Test Accuracy = 0.9278\n",
      "Epoch 352: Loss = 0.2655, Test Accuracy = 0.9278\n",
      "Epoch 353: Loss = 0.2652, Test Accuracy = 0.9277\n",
      "Epoch 354: Loss = 0.2649, Test Accuracy = 0.9280\n",
      "Epoch 355: Loss = 0.2646, Test Accuracy = 0.9281\n",
      "Epoch 356: Loss = 0.2644, Test Accuracy = 0.9282\n",
      "Epoch 357: Loss = 0.2641, Test Accuracy = 0.9284\n",
      "Epoch 358: Loss = 0.2638, Test Accuracy = 0.9285\n",
      "Epoch 359: Loss = 0.2635, Test Accuracy = 0.9285\n",
      "Epoch 360: Loss = 0.2633, Test Accuracy = 0.9285\n",
      "Epoch 361: Loss = 0.2630, Test Accuracy = 0.9285\n",
      "Epoch 362: Loss = 0.2627, Test Accuracy = 0.9288\n",
      "Epoch 363: Loss = 0.2624, Test Accuracy = 0.9288\n",
      "Epoch 364: Loss = 0.2622, Test Accuracy = 0.9287\n",
      "Epoch 365: Loss = 0.2619, Test Accuracy = 0.9287\n",
      "Epoch 366: Loss = 0.2616, Test Accuracy = 0.9289\n",
      "Epoch 367: Loss = 0.2613, Test Accuracy = 0.9290\n",
      "Epoch 368: Loss = 0.2611, Test Accuracy = 0.9292\n",
      "Epoch 369: Loss = 0.2608, Test Accuracy = 0.9294\n",
      "Epoch 370: Loss = 0.2605, Test Accuracy = 0.9294\n",
      "Epoch 371: Loss = 0.2603, Test Accuracy = 0.9295\n",
      "Epoch 372: Loss = 0.2600, Test Accuracy = 0.9297\n",
      "Epoch 373: Loss = 0.2597, Test Accuracy = 0.9297\n",
      "Epoch 374: Loss = 0.2594, Test Accuracy = 0.9297\n",
      "Epoch 375: Loss = 0.2592, Test Accuracy = 0.9298\n",
      "Epoch 376: Loss = 0.2589, Test Accuracy = 0.9298\n",
      "Epoch 377: Loss = 0.2586, Test Accuracy = 0.9299\n",
      "Epoch 378: Loss = 0.2584, Test Accuracy = 0.9302\n",
      "Epoch 379: Loss = 0.2581, Test Accuracy = 0.9302\n",
      "Epoch 380: Loss = 0.2578, Test Accuracy = 0.9305\n",
      "Epoch 381: Loss = 0.2576, Test Accuracy = 0.9305\n",
      "Epoch 382: Loss = 0.2573, Test Accuracy = 0.9306\n",
      "Epoch 383: Loss = 0.2570, Test Accuracy = 0.9307\n",
      "Epoch 384: Loss = 0.2568, Test Accuracy = 0.9307\n",
      "Epoch 385: Loss = 0.2565, Test Accuracy = 0.9308\n",
      "Epoch 386: Loss = 0.2563, Test Accuracy = 0.9307\n",
      "Epoch 387: Loss = 0.2560, Test Accuracy = 0.9307\n",
      "Epoch 388: Loss = 0.2557, Test Accuracy = 0.9307\n",
      "Epoch 389: Loss = 0.2555, Test Accuracy = 0.9307\n",
      "Epoch 390: Loss = 0.2552, Test Accuracy = 0.9308\n",
      "Epoch 391: Loss = 0.2549, Test Accuracy = 0.9308\n",
      "Epoch 392: Loss = 0.2547, Test Accuracy = 0.9308\n",
      "Epoch 393: Loss = 0.2544, Test Accuracy = 0.9308\n",
      "Epoch 394: Loss = 0.2542, Test Accuracy = 0.9308\n",
      "Epoch 395: Loss = 0.2539, Test Accuracy = 0.9308\n",
      "Epoch 396: Loss = 0.2536, Test Accuracy = 0.9308\n",
      "Epoch 397: Loss = 0.2534, Test Accuracy = 0.9308\n",
      "Epoch 398: Loss = 0.2531, Test Accuracy = 0.9307\n",
      "Epoch 399: Loss = 0.2529, Test Accuracy = 0.9309\n",
      "Epoch 400: Loss = 0.2526, Test Accuracy = 0.9309\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo và huấn luyện mạng\n",
    "nn = NeuralNetwork(input_size=784, hidden_size=128, output_size=10, learning_rate=0.3)\n",
    "nn.train(x_train, y_train, x_test, y_test, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0262c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_info = {\"weights\": [nn.W1.tolist(), nn.W2.tolist()],\n",
    "           \"biases\": [nn.b1.tolist(), nn.b2.tolist()],\n",
    "           \"learning_rate\": nn.lr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddc90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Lưu thông tin mạng vào file JSON\n",
    "with open('nn_info.json', 'w') as f:\n",
    "    json.dump(nn_info, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
